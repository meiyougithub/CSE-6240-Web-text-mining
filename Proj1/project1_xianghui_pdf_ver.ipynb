{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Generative Adversarial Networks (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## by Xianghui Gu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative Adversarial Network (GAN) is a very popular semi-supervised learning model in recent years. It was first introduced by Ian Goodfellow in 2014. This blog is based on $\\textit{NIPS 2016 Tutorial: Generative Adversarial Networks (Ian Goodfellow)}$ in general. The blog will introduce the background, application and principle of why it works. Furthermore, the blog will use MNIST to implement a simple GAN and also a trial of GAN application combined with autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the name of this method. 'G' stands for generative modeling, 'A' stands for the adversarial training, and 'N' stands for the network where a piece of plain data turns into an almost-real data as expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 'G': Generative Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generative model is a model for randomly generating observable data values, typically given some hidden parameters. It specifies a joint probability distribution over observation and label sequences. Unlike discrimitive modeling which learns $p(x|z)$, generative modeling focus more on $p(x,z).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](code/discriminative_vs_generative.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Source: https://duphan.wordpress.com/tag/generative-model/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many reasons to apply generative modeling. Its advantages include:\n",
    "- can represent and manipulate high-dimensional probability distributions\n",
    "- can be trained with missing data and can provide predictions on inputs that are missing data\n",
    "- can work with multi-modal outputs\n",
    "- can generate realistic samples from some distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 'A': Adversarial Training & Minimax Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of Adversarial Training has a counterpart in game theory, called minimax game. The goal is minimizing the score of opponent as well as maximizing self's score. \n",
    "\n",
    "$$\\Theta^{(G)*}=\\arg\\min_{\\Theta^{(G)}} \\max_{\\Theta^{(D)}} V(\\Theta^{(D)},\\Theta^{(G)})$$\n",
    "\n",
    "Similarly, Adversarial Training in GAN is like two opponents compete with each other in the training model. Imagine a game between two players. One of them is called $G$ (the $generator$). $G$ creates samples that are intended to come from the same distribution as the training data. The other player is called $D$ (the $discriminator$). $D$ examines samples to determine whether they are real or fake. $D$ learns using traditional supervised learning techniques, dividing inputs into two classes (real or fake). $G$ is trained to fool $D$. The goal of $G$ is to make $D$ behaves like guessing instead of classifying the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classic way of thinking this game: $G$ is a counterfeiter, trying to make fake money, and $D$ is a cop , trying to allow real money and catch fake money. To succeed in this game, $G$ must learn to make fake money that is indistinguishable from real money."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 'N': Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN combines neural network with generative modeling and adversarial training. In general, both $D$ and $G$ have their own neural network: one for classifying real and fake data, one for making fake data look real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN has a wide range of applications. Here we introduce two applications on images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Image Generation from AIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bunch of noise can be turned into an image we want under the magic of generator. The figure below is a set of cute outputs generated by $G$ trained on animation datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](code/loli.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Source: https://github.com/mattya/chainer-DCGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Image Arithmetics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trials on feature vector arithmetics shows a rich linear structure in representation space. Further exploring and developing vector arithmetic could dramatically reduce the amount of data needed for conditional generative modeling of complex image distributions. The figure below illustrates how to make a \"smiling man\" from \"similing woman\", \"neutral woman\" and \"neutral man\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](code/faces.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Source: Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, by\n",
    "Alec Radford, Luke Metz, Soumith Chintala)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Principle of GAN: How it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the background part, we offer a general idea of the components of GAN. In this section, we'll talk more about how GAN works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\textbf{Basic idea}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN is the relection of adversarial thinking in neural network. It includes two neural networks. One is the Generator network, which aims at making fake data look real; the other is the Discriminator network, which aims at telling the difference with fake data from the real data. The latter outputs a number between 0 and 1, which stands for the probability that input is from real data. For instance, the ouput 1 stands for real data, and 0 stands for fake data. In theory, with the convergence of training, each piece of data generated by the Generator network should be \"hard\" enough for the Discriminator network to decide whether real or not. Hence, the output of the latter should be 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below illustrates the task of $D$ (Discriminator network) and $G$ (Generator network) in GAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](code/d_g.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Source: NIPS 2016 Tutorial: Generative Adversarial Networks, by Ian Goodfellow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\textbf{Objective}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the real data $x$ and fake data $z$, the goal is to maximize $V_D,V_G$ for $D$ and $G$ respectively. The goals used in the training network are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$V_D=\\log(D(x))+\\log(1âˆ’D(G(z)))$$\n",
    "$$V_G=\\log(D(G(z)))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why the goals are not \"symmetric\" is that in $V_G=\\log(D(G(z)))+\\log(1-D(x))$, the second term has nothing to do with $G$, hence omitted in maximization for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Toy Examples of GAN on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The toy examples are mainly inspired by $\\textit{Generative Adversarial Nets in TensorFlow}$ (by Eric Jang) and Nathan Lintz's implementation.\n",
    "\n",
    "(Source: https://github.com/nlintz/TensorFlow-Tutorials/blob/master)\n",
    "\n",
    "(Source: http://blog.evjang.com/2016/06/generative-adversarial-nets-in.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 One hidden layer implementation with 200 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the MNIST data from tensorflow tutorial, whose size is (55000, 784)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "images = mnist.train.images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\textbf{Weight Initialization by Xavier}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For other distribution initialization (such as normal distribution), the neural network may perform bad or even fail due to trivial weight or exploding weight.\n",
    "\n",
    "For example, I tried normal distribution in this setting, the numpy returns error: \n",
    "\n",
    "$\\textit{UserWarning: Warning: converting a masked element to nan.}$\n",
    "\n",
    "Hence, Xavier distribution is suitable in this situation. Andy's blog introduces $\\textbf{Xavier initialization}$ which help signals reach deep into the network.\n",
    "\n",
    "If the weights in a network start too small, then the signal shrinks as it passes through each layer until itâ€™s too tiny to be useful.\n",
    "If the weights in a network start too large, then the signal grows as it passes through each layer until itâ€™s too massive to be useful.\n",
    "Xavier initialization makes sure the weights are â€˜just rightâ€™, keeping the signal in a reasonable range of values through many layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Source: http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xavier_initializer(shape):\n",
    "    return tf.random_normal(shape=shape, stddev=1/shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\textbf{MLP setting}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set the components in MLP (multi-layer perceptrons). There are two set of parameters: one set for $D$ and one for $G$. The neurons are set to be 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_layer = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator parameters: take 128 latent variables as the noise source for generating fake figures (28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_size = 128\n",
    "g_output_size = 784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disciminator parameters: try to detect whether the input figure of 28*28 is real or fake (output: 1/0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_size = 784\n",
    "d_output_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eric Jang's blog put all the parameters in a function. For debugging purpose, we don't follow it here. We write the weights and their initialization globally as Nathan did, so that we can detect exploding weights. $w_i$ stands for the coefficients corresponding to each node, while $b_i$ stands for the offset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_weights = {\n",
    "    'w1': tf.Variable(xavier_initializer(shape=(z_size, one_layer))),\n",
    "    'b1': tf.Variable(tf.zeros(shape=[one_layer])),\n",
    "    'w2': tf.Variable(xavier_initializer(shape=(one_layer, g_output_size))),\n",
    "    'b2': tf.Variable(tf.zeros(shape=[g_output_size]))\n",
    "}\n",
    "\n",
    "d_weights ={\n",
    "    'w1': tf.Variable(xavier_initializer(shape=(x_size, one_layer))),\n",
    "    'b1': tf.Variable(tf.zeros(shape=[one_layer])),\n",
    "    'w2': tf.Variable(xavier_initializer(shape=(one_layer, d_output_size))),\n",
    "    'b2': tf.Variable(tf.zeros(shape=[d_output_size]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write out the neural network model. $l_i$ stands for the temporary result after computing $i^{th}$ layer. We use tanh here as did in Eric Jang's blog, but use sigmoid to control the answer in range of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gen(z, w=g_weights):\n",
    "    l1 = tf.nn.tanh(tf.matmul(z, w['w1']) + w['b1'])\n",
    "    return tf.sigmoid(tf.matmul(l1, w['w2']) + w['b2'])\n",
    "\n",
    "def Dis(x, w=d_weights):\n",
    "    l1 = tf.nn.tanh(tf.matmul(x, w['w1']) + w['b1'])\n",
    "    return tf.sigmoid(tf.matmul(l1, w['w2']) + w['b2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to prepare for the input and output of the MLP model. We use placeholder $d_{input}$ and $g_{input}$ to hold the input size for neural network of $D$ and $G$ respectively. Since we don't know how many instances to generate or to test, we set the row parameter to $None$. The output of $G$ is obtained by applying function $\\textit{Gen}$ directly on latent vector $z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_input = tf.placeholder('float', shape=(None, x_size))\n",
    "g_input = tf.placeholder('float', shape=(None, z_size))\n",
    "g_output = Gen(g_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\textbf{Objective of D and G}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective function for $D$ and $G$ are:\n",
    "$$\\max V_D=\\log(D(x))+\\log(1âˆ’D(G(z)))$$\n",
    "$$\\max V_G=\\log(D(G(z)))$$\n",
    "Hence, within a batch, we take the mean of all the scores as a standard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_objective = tf.reduce_mean(tf.log(Dis(Gen(g_input))))\n",
    "D_objective = tf.reduce_mean(tf.log(Dis(d_input)) + tf.log(1 - Dis(Gen(g_input))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eric Jang uses momentum_optimizer to minimize the objective. It is flexible to modify the learning rate and step, but complicated. For simplicity, this blog uses AdamOptimizer to find optimum as Nathan did. Note the objective should be negative since we are maximizing the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_opt = tf.train.AdamOptimizer().minimize(-G_objective, var_list=g_weights.values())\n",
    "D_opt = tf.train.AdamOptimizer().minimize(-D_objective, var_list=d_weights.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\textbf{Run the model and plot samples}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use epoch of 30,000 and batch size of 128. As suggested in Eric Jang's blog, $D$ might need more rounds to learn in case $G$ learns too fast. For simplicity, we keep $D_{rounds}=1$ for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "epochs = 30000\n",
    "batch_size = 128\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "D_rounds = 1\n",
    "\n",
    "for _ in tqdm.tqdm(range(epochs)):\n",
    "    sess.run(G_opt, {\n",
    "        g_input: np.random.normal(size=(batch_size, z_size))           \n",
    "    })\n",
    "    for _ in range(D_rounds):\n",
    "        sess.run(D_opt, {\n",
    "            d_input: images[np.random.choice(range(len(images)), batch_size)].reshape(batch_size, x_size),\n",
    "            g_input: np.random.normal(size=(batch_size, z_size))\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "samples = 64\n",
    "side = int(math.sqrt(samples))\n",
    "\n",
    "fakes = sess.run(g_output,{g_input:np.random.normal(size=(samples, z_size))})\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "\n",
    "for i in range(samples):\n",
    "    plt.subplot(side,side,i+1)\n",
    "    fake = fakes[i,:]\n",
    "    plt.imshow(fake.reshape(28, 28), cmap='gray')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](code/toy01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the figure above, the most numbers look like 3 and 8, and there are some 2 and 5. Under this settings, 3 and 8 have a large domain in the space implied by the neural network. More sampling and training may help generate more numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Two hidden layer implementation with 100 neurons for each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see whether more perceptrons work better or more layers work better in GAN, we made a second toy example using two hidden layers with 100 neurons each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_layer = 100\n",
    "second_layer = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accordingly, the weights and the models are modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_weights = {\n",
    "    'w1': tf.Variable(xavier_initializer(shape=(z_size, first_layer))),\n",
    "    'b1': tf.Variable(tf.zeros(shape=[first_layer])),\n",
    "    'w2': tf.Variable(xavier_initializer(shape=(first_layer, second_layer))),\n",
    "    'b2': tf.Variable(tf.zeros(shape=[second_layer])),\n",
    "    'w3': tf.Variable(xavier_initializer(shape=(second_layer, g_output_size))),\n",
    "    'b3': tf.Variable(tf.zeros(shape=[g_output_size]))\n",
    "}\n",
    "\n",
    "d_weights ={\n",
    "    'w1': tf.Variable(xavier_initializer(shape=(x_size, first_layer))),\n",
    "    'b1': tf.Variable(tf.zeros(shape=[first_layer])),\n",
    "    'w2': tf.Variable(xavier_initializer(shape=(first_layer, second_layer))),\n",
    "    'b2': tf.Variable(tf.zeros(shape=[second_layer])),\n",
    "    'w3': tf.Variable(xavier_initializer(shape=(second_layer, d_output_size))),\n",
    "    'b3': tf.Variable(tf.zeros(shape=[d_output_size]))\n",
    "}\n",
    "\n",
    "def Gen(z, w=g_weights):\n",
    "    l1 = tf.nn.tanh(tf.matmul(z, w['w1']) + w['b1'])\n",
    "    l2 = tf.nn.tanh(tf.matmul(l1, w['w2']) + w['b2'])\n",
    "    return tf.sigmoid(tf.matmul(l2, w['w3']) + w['b3'])\n",
    "\n",
    "def Dis(x, w=d_weights):\n",
    "    l1 = tf.nn.tanh(tf.matmul(x, w['w1']) + w['b1'])\n",
    "    l2 = tf.nn.tanh(tf.matmul(l1, w['w2']) + w['b2'])\n",
    "    return tf.sigmoid(tf.matmul(l2, w['w3']) + w['b3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other part of MLP modeling is the same. Let's have a quick review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_input = tf.placeholder('float', shape=(None, x_size))\n",
    "g_input = tf.placeholder('float', shape=(None, z_size))\n",
    "g_output = Gen(g_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_objective = tf.reduce_mean(tf.log(Dis(Gen(g_input))))\n",
    "D_objective = tf.reduce_mean(tf.log(Dis(d_input)) + tf.log(1 - Dis(Gen(g_input))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_opt = tf.train.AdamOptimizer().minimize(-G_objective, var_list=g_weights.values())\n",
    "D_opt = tf.train.AdamOptimizer().minimize(-D_objective, var_list=d_weights.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "epochs = 30000\n",
    "batch_size = 128\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "D_rounds = 1\n",
    "\n",
    "for _ in tqdm.tqdm(range(epochs)):\n",
    "    sess.run(G_opt, {\n",
    "        g_input: np.random.normal(size=(batch_size, z_size))           \n",
    "    })\n",
    "    for _ in range(D_rounds):\n",
    "        sess.run(D_opt, {\n",
    "            d_input: images[np.random.choice(range(len(images)), batch_size)].reshape(batch_size, x_size),\n",
    "            g_input: np.random.normal(size=(batch_size, z_size))\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "samples = 64\n",
    "side = int(math.sqrt(samples))\n",
    "\n",
    "fakes = sess.run(g_output,{g_input:np.random.normal(size=(samples, z_size))})\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "\n",
    "for i in range(samples):\n",
    "    plt.subplot(side,side,i+1)\n",
    "    fake = fakes[i,:]\n",
    "    plt.imshow(fake.reshape(28, 28), cmap='gray')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](code/toy02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the figure above, we can tell 1,2,3,4,5,7,8,9. It seems like two layer works better than one layer given the same number of hidden neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Combination of autoencoder and GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking of self-supervising machine learning algorithms, it reminds me of autoencoder building. Autoencoder can extract the features of an image, and compress the information by encoding. If we change the real input into encoded (compressed) images, will GAN learn faster or generate better output since features have already been summarized? If it will, it may be a good idea that GAN generates an encoded image and in turn decoder reconstructs it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\textbf{Set and build autoencoder}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with building an autoencoder on keras workframe. For simplicity, we train and test the autoencoder by keras MNIST datasets. The building of autoencoder is based on keras tutorial.\n",
    "(Source: https://blog.keras.io/building-autoencoders-in-keras.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, label_train), (x_test, label_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the train/test images into (60000, 28, 28, 1) and (10000, 28, 28, 1) respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1)) \n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autoencoder takes the original image as input, which is (28,28,1). The encoded message is (4,4,8) which is 128-dimensional. The decoded message should have the same dimension as the input. Due to the learning rate of autoencoder and computational resource, we use 20% of the training set and full testing test as validation. The epoch is set to be 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "# select 10% for training\n",
    "small_ratio = 0.2\n",
    "small_ind = np.random.choice(len(x_train), int(len(x_train)*small_ratio), replace = False)\n",
    "\n",
    "x_train_small = x_train[small_ind]\n",
    "\n",
    "history = autoencoder.fit(x_train_small, x_train_small,\n",
    "                epochs=20,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model of encoding original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode the first image in the training dataset as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encode_sample = encoder.predict(x_train[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape is (4,4,8). Then, we can have a sight of how encoded images look like (here we reshape the encoded image into 16*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(encode_sample.reshape(16,8),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](code/junk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far I didn't find a nice way to formulate the decoder from encoded message. Let's do it in brutal force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(4,4,8))\n",
    "# retrieve the layer of the autoencoder model\n",
    "temp = autoencoder.layers\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, temp[-1](temp[-2](temp[-3](temp[-4](temp[-5](temp[-6](temp[-7](encoded_input))))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the decoded image from encoded message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decode_sample = decoder.predict(encode_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(decode_sample.reshape(28,28),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](code/dirty5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with the original message, we can find the character looks dimmer, which may be attributed to loss in encoding/decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0].reshape(28,28),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](code/clean5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\textbf{GAN using encoded images with one hidden layer of 200 neurons}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, we directly use the foundation in Toy example 4.1, which is one hidden layer with 200 neurons. Let's have a quick review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_layer = 200\n",
    "\n",
    "z_size = 128\n",
    "g_output_size = 128\n",
    "\n",
    "x_size = 128\n",
    "d_output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_weights = {\n",
    "    'w1': tf.Variable(xavier_initializer(shape=(z_size, one_layer))),\n",
    "    'b1': tf.Variable(tf.zeros(shape=[one_layer])),\n",
    "    'w2': tf.Variable(xavier_initializer(shape=(one_layer, g_output_size))),\n",
    "    'b2': tf.Variable(tf.zeros(shape=[g_output_size]))\n",
    "}\n",
    "\n",
    "d_weights ={\n",
    "    'w1': tf.Variable(xavier_initializer(shape=(x_size, one_layer))),\n",
    "    'b1': tf.Variable(tf.zeros(shape=[one_layer])),\n",
    "    'w2': tf.Variable(xavier_initializer(shape=(one_layer, d_output_size))),\n",
    "    'b2': tf.Variable(tf.zeros(shape=[d_output_size]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gen(z, w=g_weights):\n",
    "    l1 = tf.nn.tanh(tf.matmul(z, w['w1']) + w['b1'])\n",
    "    return tf.sigmoid(tf.matmul(l1, w['w2']) + w['b2'])\n",
    "\n",
    "def Dis(x, w=d_weights):\n",
    "    l1 = tf.nn.tanh(tf.matmul(x, w['w1']) + w['b1'])\n",
    "    return tf.sigmoid(tf.matmul(l1, w['w2']) + w['b2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_input = tf.placeholder('float', shape=(None, x_size))\n",
    "g_input = tf.placeholder('float', shape=(None, z_size))\n",
    "g_output = Gen(g_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_objective = tf.reduce_mean(tf.log(Dis(Gen(g_input))))\n",
    "D_objective = tf.reduce_mean(tf.log(Dis(d_input)) + tf.log(1 - Dis(Gen(g_input))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_opt = tf.train.AdamOptimizer().minimize(-G_objective, var_list=g_weights.values())\n",
    "D_opt = tf.train.AdamOptimizer().minimize(-D_objective, var_list=d_weights.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the dataset and forge into the size of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enc_images = encoder.predict(images.reshape(len(images),28,28,1)).reshape(len(images),g_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the GAN using the encoded message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "epochs = 30000\n",
    "batch_size = 128\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "D_rounds = 1\n",
    "\n",
    "for _ in tqdm.tqdm(range(epochs)):\n",
    "    sess.run(G_opt, {\n",
    "        g_input: np.random.normal(size=(batch_size, z_size))           \n",
    "    })\n",
    "    for _ in range(D_rounds):\n",
    "        sess.run(D_opt, {\n",
    "            d_input: enc_images[np.random.choice(range(len(enc_images)), batch_size)].reshape(batch_size, x_size),\n",
    "            g_input: np.random.normal(size=(batch_size, z_size))\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a view of what GAN generates based on the encoding message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "sample_size = 64\n",
    "dim = (int(math.sqrt(sample_size)),int(math.sqrt(sample_size)))\n",
    "plt.figure(figsize=(16,8))\n",
    "img = sess.run(g_output, {g_input: np.random.normal(size=(sample_size, z_size))})\n",
    "img_mat = np.empty([sample_size, g_output_size])\n",
    "\n",
    "for i in range(sample_size):\n",
    "    plt.subplot(dim[0],dim[1],i+1)\n",
    "    image = img[i,:]\n",
    "    img_mat[i,:] = image\n",
    "    plt.imshow(image.reshape(16, 8), cmap='gray')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](code/toy03-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xxx = decoder.predict(img_mat.reshape(len(img_mat),4,4,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "for i in range(sample_size):\n",
    "    plt.subplot(dim[0],dim[1],i+1)\n",
    "    image = xxx[i,:]\n",
    "    plt.imshow(image.reshape(28,28), cmap='gray')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](code/toy03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the figure above, the combination of GAN and autoencoder didn't work as expected. This may due to the double error from encoding/decoding as well as from GAN. Since we control the GAN part compared with Toy example 4.1, the error from autoencoder might be the main cause."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm, let's try epochs = 50,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "epochs = 50000\n",
    "batch_size = 128\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "D_rounds = 1\n",
    "\n",
    "for _ in tqdm.tqdm(range(epochs)):\n",
    "    sess.run(G_opt, {\n",
    "        g_input: np.random.normal(size=(batch_size, z_size))           \n",
    "    })\n",
    "    for _ in range(D_rounds):\n",
    "        sess.run(D_opt, {\n",
    "            d_input: enc_images[np.random.choice(range(len(enc_images)), batch_size)].reshape(batch_size, x_size),\n",
    "            g_input: np.random.normal(size=(batch_size, z_size))\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "img2 = sess.run(g_output, {g_input: np.random.normal(size=(sample_size, z_size))})\n",
    "img_mat2 = np.empty([sample_size, g_output_size])\n",
    "\n",
    "for i in range(sample_size):\n",
    "    image = img2[i,:]\n",
    "    img_mat2[i,:] = image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yyy = decoder.predict(img_mat2.reshape(len(img_mat),4,4,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "for i in range(sample_size):\n",
    "    plt.subplot(dim[0],dim[1],i+1)\n",
    "    image = yyy[i,:]\n",
    "    plt.imshow(image.reshape(28,28), cmap='gray')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](code/toy03-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure displayed shows it is far from convergence. Hence, encoding in such compression ratio did not perform well combined with GAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Discussion and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the explanation and implementation of GAN, I hope you can have a general idea of GAN. It is useful and powerful, and has many fun and profitable applications. In addition to the trials displayed in the blog, I've run several rounds with different parameters. The thoughts are summarized below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With small number of epochs, the output almost looks the same. One can't discriminate the number (it looks like the combination of all digits)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Due to compuational resources, I didn't try a wide range of additional rounds for $D$ ($D$ may be trained more rounds than $G$ to prevent that $G$ grows faster.) Under the settings in the blog, I didn't tell the difference between $D_{rounds}=1$ and $D_{rounds}=5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's hard to pick the right set of MLP parameters, initialization distributions and epochs. Any improper parameter can lead to exploding weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From Toy example 4.1 and 4.2, under this set of parameters, two layer model performs better than one layer model given the same number of neurons in GAN. Additional layer may consider more nonlinear relationship than just one layer, which might be the cause for better performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From Toy example 4.3, the combination of encoding/decoding and GAN might be too brutal. The error from encoding/decoding and GAN can both harm the performance of generating digits. The paper, $\\textit{Adversarial Autoencoders}$ (by Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, Brendan Frey), introduces combination of VAE decoder and GAN which has a much better performance.    (Source: https://arxiv.org/pdf/1511.05644)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "cse6240",
   "language": "python",
   "name": "cse6240"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
