{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 - Q2 Xianghui Gu (xgu72, 903248583)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim, csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- read preprocessed train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "clean_train_reviews = []\n",
    "with open('clean_train_reviews.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        clean_train_reviews.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_test_reviews = []\n",
    "with open('clean_test_reviews.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        clean_test_reviews.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- obtain the mapping {id:word} from training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "id2word = Dictionary(clean_train_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- return a transformed corpus which records the prossible class as well as the probability to be in that class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topicModeling(reviews, test_reviews, num_topics):\n",
    "    corpus = [id2word.doc2bow(row) for row in reviews]\n",
    "    test_corpus = [id2word.doc2bow(row) for row in test_reviews]\n",
    "    lda = gensim.models.ldamodel.LdaModel(corpus = corpus, id2word = id2word, num_topics = num_topics)\n",
    "    mat = lda[corpus]\n",
    "    test_mat = lda[test_corpus]\n",
    "    return (mat, test_mat, lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3, X3_test, lda3 = topicModeling(clean_train_reviews, clean_test_reviews, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X4, X4_test, lda4 = topicModeling(clean_train_reviews, clean_test_reviews, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- top 10 topics for method 3 (lda with 10 topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.042*\"movie\" + 0.012*\"like\" + 0.011*\"one\" + 0.011*\"film\" + 0.009*\"really\" + 0.009*\"good\" + 0.008*\"bad\" + 0.007*\"even\" + 0.007*\"see\" + 0.007*\"time\"'),\n",
       " (1,\n",
       "  '0.024*\"movie\" + 0.016*\"film\" + 0.011*\"good\" + 0.010*\"one\" + 0.010*\"great\" + 0.009*\"like\" + 0.007*\"funny\" + 0.007*\"well\" + 0.006*\"see\" + 0.006*\"really\"'),\n",
       " (2,\n",
       "  '0.020*\"show\" + 0.013*\"series\" + 0.007*\"like\" + 0.007*\"episode\" + 0.006*\"one\" + 0.006*\"first\" + 0.005*\"tv\" + 0.005*\"time\" + 0.005*\"would\" + 0.004*\"episodes\"'),\n",
       " (3,\n",
       "  '0.006*\"man\" + 0.005*\"one\" + 0.004*\"police\" + 0.004*\"film\" + 0.004*\"wife\" + 0.004*\"good\" + 0.003*\"movie\" + 0.003*\"role\" + 0.003*\"father\" + 0.003*\"character\"'),\n",
       " (4,\n",
       "  '0.019*\"film\" + 0.005*\"one\" + 0.005*\"story\" + 0.004*\"also\" + 0.004*\"well\" + 0.003*\"like\" + 0.003*\"character\" + 0.003*\"characters\" + 0.003*\"love\" + 0.003*\"much\"'),\n",
       " (5,\n",
       "  '0.014*\"film\" + 0.008*\"one\" + 0.004*\"movie\" + 0.004*\"well\" + 0.003*\"time\" + 0.003*\"see\" + 0.003*\"like\" + 0.003*\"people\" + 0.003*\"still\" + 0.003*\"way\"'),\n",
       " (6,\n",
       "  '0.009*\"film\" + 0.008*\"one\" + 0.004*\"two\" + 0.004*\"like\" + 0.004*\"get\" + 0.003*\"also\" + 0.003*\"scene\" + 0.003*\"even\" + 0.003*\"story\" + 0.003*\"little\"'),\n",
       " (7,\n",
       "  '0.018*\"film\" + 0.010*\"one\" + 0.007*\"movie\" + 0.007*\"like\" + 0.006*\"bad\" + 0.005*\"even\" + 0.005*\"horror\" + 0.005*\"would\" + 0.004*\"make\" + 0.004*\"good\"'),\n",
       " (8,\n",
       "  '0.010*\"film\" + 0.010*\"one\" + 0.005*\"best\" + 0.004*\"also\" + 0.004*\"great\" + 0.004*\"well\" + 0.004*\"two\" + 0.004*\"cast\" + 0.003*\"role\" + 0.003*\"time\"'),\n",
       " (9,\n",
       "  '0.017*\"film\" + 0.008*\"one\" + 0.006*\"life\" + 0.006*\"story\" + 0.005*\"people\" + 0.005*\"movie\" + 0.005*\"like\" + 0.005*\"us\" + 0.004*\"time\" + 0.004*\"would\"')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda3.print_topics(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- topic 20 topics in method 4 (lda with 20 topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.024*\"film\" + 0.008*\"one\" + 0.006*\"father\" + 0.005*\"mother\" + 0.005*\"story\" + 0.005*\"woman\" + 0.004*\"young\" + 0.004*\"also\" + 0.004*\"two\" + 0.004*\"man\"'),\n",
       " (1,\n",
       "  '0.029*\"film\" + 0.006*\"one\" + 0.005*\"man\" + 0.005*\"story\" + 0.004*\"also\" + 0.004*\"films\" + 0.004*\"like\" + 0.004*\"well\" + 0.004*\"director\" + 0.004*\"character\"'),\n",
       " (2,\n",
       "  '0.014*\"film\" + 0.007*\"good\" + 0.006*\"one\" + 0.006*\"killer\" + 0.005*\"movie\" + 0.005*\"like\" + 0.004*\"films\" + 0.004*\"well\" + 0.003*\"get\" + 0.003*\"first\"'),\n",
       " (3,\n",
       "  '0.016*\"film\" + 0.006*\"one\" + 0.005*\"like\" + 0.004*\"play\" + 0.004*\"john\" + 0.004*\"actor\" + 0.004*\"well\" + 0.003*\"see\" + 0.003*\"movie\" + 0.003*\"would\"'),\n",
       " (4,\n",
       "  '0.016*\"film\" + 0.006*\"one\" + 0.005*\"films\" + 0.004*\"like\" + 0.004*\"david\" + 0.004*\"world\" + 0.003*\"director\" + 0.003*\"von\" + 0.003*\"much\" + 0.003*\"art\"'),\n",
       " (5,\n",
       "  '0.007*\"one\" + 0.006*\"film\" + 0.004*\"town\" + 0.004*\"columbo\" + 0.004*\"war\" + 0.004*\"arthur\" + 0.004*\"men\" + 0.004*\"charlie\" + 0.003*\"also\" + 0.003*\"soldiers\"'),\n",
       " (6,\n",
       "  '0.033*\"movie\" + 0.013*\"film\" + 0.012*\"one\" + 0.012*\"like\" + 0.009*\"bad\" + 0.008*\"good\" + 0.008*\"even\" + 0.007*\"would\" + 0.007*\"really\" + 0.006*\"time\"'),\n",
       " (7,\n",
       "  '0.015*\"film\" + 0.007*\"people\" + 0.006*\"life\" + 0.006*\"one\" + 0.005*\"us\" + 0.005*\"story\" + 0.004*\"would\" + 0.004*\"world\" + 0.004*\"two\" + 0.004*\"time\"'),\n",
       " (8,\n",
       "  '0.013*\"game\" + 0.010*\"film\" + 0.006*\"one\" + 0.006*\"good\" + 0.006*\"van\" + 0.005*\"great\" + 0.005*\"like\" + 0.004*\"movie\" + 0.004*\"even\" + 0.004*\"games\"'),\n",
       " (9,\n",
       "  '0.007*\"davis\" + 0.006*\"film\" + 0.006*\"tony\" + 0.004*\"character\" + 0.004*\"gandhi\" + 0.004*\"characters\" + 0.004*\"mary\" + 0.004*\"like\" + 0.003*\"time\" + 0.003*\"sex\"'),\n",
       " (10,\n",
       "  '0.007*\"japanese\" + 0.007*\"one\" + 0.006*\"match\" + 0.005*\"anime\" + 0.004*\"russian\" + 0.004*\"japan\" + 0.004*\"hardy\" + 0.004*\"joe\" + 0.003*\"team\" + 0.003*\"batman\"'),\n",
       " (11,\n",
       "  '0.009*\"film\" + 0.005*\"one\" + 0.004*\"tarzan\" + 0.004*\"earth\" + 0.004*\"planet\" + 0.003*\"also\" + 0.003*\"people\" + 0.003*\"man\" + 0.003*\"would\" + 0.003*\"time\"'),\n",
       " (12,\n",
       "  '0.007*\"musical\" + 0.006*\"one\" + 0.006*\"dance\" + 0.005*\"kelly\" + 0.005*\"comedy\" + 0.004*\"film\" + 0.004*\"dancing\" + 0.004*\"two\" + 0.004*\"george\" + 0.004*\"love\"'),\n",
       " (13,\n",
       "  '0.031*\"movie\" + 0.013*\"film\" + 0.012*\"one\" + 0.010*\"story\" + 0.010*\"great\" + 0.008*\"love\" + 0.007*\"like\" + 0.007*\"time\" + 0.006*\"see\" + 0.006*\"well\"'),\n",
       " (14,\n",
       "  '0.010*\"like\" + 0.009*\"one\" + 0.009*\"movie\" + 0.006*\"even\" + 0.005*\"good\" + 0.004*\"film\" + 0.004*\"fi\" + 0.004*\"sci\" + 0.004*\"bad\" + 0.004*\"looks\"'),\n",
       " (15,\n",
       "  '0.009*\"one\" + 0.008*\"film\" + 0.008*\"war\" + 0.006*\"movie\" + 0.005*\"life\" + 0.004*\"well\" + 0.004*\"even\" + 0.004*\"man\" + 0.003*\"dan\" + 0.003*\"time\"'),\n",
       " (16,\n",
       "  '0.017*\"film\" + 0.010*\"one\" + 0.008*\"horror\" + 0.006*\"films\" + 0.006*\"like\" + 0.005*\"good\" + 0.005*\"really\" + 0.005*\"killer\" + 0.004*\"action\" + 0.004*\"slasher\"'),\n",
       " (17,\n",
       "  '0.026*\"show\" + 0.016*\"series\" + 0.008*\"episode\" + 0.008*\"one\" + 0.008*\"good\" + 0.007*\"like\" + 0.007*\"great\" + 0.007*\"tv\" + 0.007*\"first\" + 0.006*\"would\"'),\n",
       " (18,\n",
       "  '0.006*\"one\" + 0.005*\"like\" + 0.004*\"keaton\" + 0.004*\"star\" + 0.004*\"also\" + 0.004*\"film\" + 0.004*\"luke\" + 0.003*\"well\" + 0.003*\"new\" + 0.003*\"time\"'),\n",
       " (19,\n",
       "  '0.019*\"movie\" + 0.012*\"horror\" + 0.009*\"film\" + 0.008*\"one\" + 0.005*\"house\" + 0.005*\"vampire\" + 0.005*\"like\" + 0.005*\"also\" + 0.004*\"movies\" + 0.004*\"see\"')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda4.print_topics(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convert a probability list to a probability matrix\n",
    "- e.g. [(3,0.3),(7.0.7)] -> [[0,0,0,0.3,0,0,0,0.7,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_bag_of_topics(row, num_topics):\n",
    "    # Pre-allocate the bag of centroids vector (for speed)\n",
    "    bag_of_topics = np.zeros(num_topics, dtype=\"float32\" )\n",
    "\n",
    "    for topic, prob in row:\n",
    "        bag_of_topics[topic] = prob\n",
    "    # Return the \"bag of centroids\"\n",
    "    return bag_of_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_topics(transformed_corpus, num_topics, output_name):\n",
    "    output = np.zeros((len(transformed_corpus), num_topics), dtype=\"float32\")\n",
    "    for pos, row in enumerate(transformed_corpus):\n",
    "        output[pos] = create_bag_of_topics(row, num_topics)\n",
    "    np.savetxt(output_name + '.out', output, delimiter=',') \n",
    "    return output\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3_out = output_topics(X3, 10, 'X3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X3_test_out = output_topics(X3_test, 10, 'X3_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X4_out = output_topics(X4, 20, 'X4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X4_test_out = output_topics(X4_test, 20, 'X4_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 20)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4_out.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "cse6240",
   "language": "python",
   "name": "cse6240"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
